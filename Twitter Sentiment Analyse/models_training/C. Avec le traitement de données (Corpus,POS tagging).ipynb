{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGas1I1Zbbcj"
   },
   "source": [
    "**Commentaire:** _Ici, nous avons choisi ici d'entraîner le modèle sur des données traitées grâce à la fonction \"create_corpus\" et en rajoutant le Pos Tagging afin d'identifier la nature de chaque mot._\n",
    "\n",
    "\n",
    "I. Importation des packages nécessaires\n",
    "\n",
    "II. Importation du jeu de données\n",
    "\n",
    "III. Séparation des données\n",
    "\n",
    "VI. Entraînement des modèles\n",
    "\n",
    "> 1. Régression logistique\n",
    "\n",
    "> 2. Naif bayésien BernoulliNB\n",
    "\n",
    "> 3. Naif bayésien MultinomialNB\n",
    "\n",
    "> 4. K plus proches voisins\n",
    "\n",
    "> 5. Arbre de décision\n",
    "\n",
    "> 6. Forêt aléatoire\n",
    "\n",
    "> 7. XGBOOST\n",
    "\n",
    "> 8. Gradient Boosting\n",
    "\n",
    "> 9. Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C-Uq-qliICM"
   },
   "source": [
    "# PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24294,
     "status": "ok",
     "timestamp": 1579410160290,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "b0Rm_gN2fvy6",
    "outputId": "4ef0df3f-b5d0-4830-ef29-631eaebae3a5"
   },
   "outputs": [],
   "source": [
    "#For Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# file_path = 'gdrive/My Drive/Colab Notebooks/SentimentAnalysisTwitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For local\n",
    "file_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KjfoTwfik7r"
   },
   "source": [
    "On enregistre les modèles entraînés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e42apQUvikjo"
   },
   "outputs": [],
   "source": [
    "trained_models_path = file_path + 'Best_models_C/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjNvVxZRiMfV"
   },
   "source": [
    "# I. Importation des packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28080,
     "status": "ok",
     "timestamp": 1579410164107,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "opecpP88fvzA",
    "outputId": "6bd07870-c6e4-4521-b444-2f4a454fd634"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize, pos_tag, sent_tokenize\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyO0C38iibyO"
   },
   "source": [
    "# II. Importation du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.split(os.getcwd())[0]+'/data/data_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYGLK8MBfvzD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path +'/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31984,
     "status": "ok",
     "timestamp": 1579410168034,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "UN_HkDJrfvzK",
    "outputId": "2114b621-faa5-4513-a1de-0642d0b91f63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tagged</th>\n",
       "      <th>clean_text_tagged_bis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot awww bummer shoulda got david carr ...</td>\n",
       "      <td>[('switchfoot', 'NN'), ('awww', 'NN'), ('bumme...</td>\n",
       "      <td>('switchfoot', 'NN'), ('awww', 'NN'), ('bummer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "      <td>[('upset', 'JJ'), ('update', 'JJ'), ('facebook...</td>\n",
       "      <td>('upset', 'JJ'), ('update', 'JJ'), ('facebook'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many times ball managed save 50...</td>\n",
       "      <td>[('kenichan', 'NNS'), ('dived', 'VBD'), ('many...</td>\n",
       "      <td>('kenichan', 'NNS'), ('dived', 'VBD'), ('many'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>[('whole', 'JJ'), ('body', 'NN'), ('feels', 'N...</td>\n",
       "      <td>('whole', 'JJ'), ('body', 'NN'), ('feels', 'NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving mad see</td>\n",
       "      <td>[('nationwideclass', 'NN'), ('behaving', 'NN')...</td>\n",
       "      <td>('nationwideclass', 'NN'), ('behaving', 'NN'),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  target         ids                          date      flag  \\\n",
       "0      0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1      1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2      2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3      3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4      4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  switchfoot awww bummer shoulda got david carr ...   \n",
       "1  upset update facebook texting might cry result...   \n",
       "2  kenichan dived many times ball managed save 50...   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                   nationwideclass behaving mad see   \n",
       "\n",
       "                                   clean_text_tagged  \\\n",
       "0  [('switchfoot', 'NN'), ('awww', 'NN'), ('bumme...   \n",
       "1  [('upset', 'JJ'), ('update', 'JJ'), ('facebook...   \n",
       "2  [('kenichan', 'NNS'), ('dived', 'VBD'), ('many...   \n",
       "3  [('whole', 'JJ'), ('body', 'NN'), ('feels', 'N...   \n",
       "4  [('nationwideclass', 'NN'), ('behaving', 'NN')...   \n",
       "\n",
       "                               clean_text_tagged_bis  \n",
       "0  ('switchfoot', 'NN'), ('awww', 'NN'), ('bummer...  \n",
       "1  ('upset', 'JJ'), ('update', 'JJ'), ('facebook'...  \n",
       "2  ('kenichan', 'NNS'), ('dived', 'VBD'), ('many'...  \n",
       "3  ('whole', 'JJ'), ('body', 'NN'), ('feels', 'NN...  \n",
       "4  ('nationwideclass', 'NN'), ('behaving', 'NN'),...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_DZHnSttdn4"
   },
   "source": [
    "# III. Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STGSZlrRtdn4"
   },
   "outputs": [],
   "source": [
    "X = df['clean_text_tagged']\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNVI6EU_tdn9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvJKTM3Ctdn_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRsUgxiv-BCi"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(vectorizer, open(trained_models_path+'vectorizer.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHg_9UEFjxpM"
   },
   "source": [
    "# VI. Entraînement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzmv7FRmtdoB"
   },
   "source": [
    "## 1. Régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42942,
     "status": "ok",
     "timestamp": 1579410179047,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "6-rjir2-tdoC",
    "outputId": "94a9e80f-d73d-4443-bb7a-c2bda5ba3c72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=0.1, penalty ='l2')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w64AUuLm3Ix"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(logreg, open(trained_models_path+'logreg.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emlwEgqJtdoW"
   },
   "source": [
    "### Avec une TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyyxor47tdoW"
   },
   "outputs": [],
   "source": [
    "X_train_tf,X_test_tf,y_train_tf,y_test_tf = train_test_split(X,y,test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpyu6cAztdoY"
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "X_train_tvec = tvec.fit_transform(X_train_tf)\n",
    "X_test_tvec = tvec.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHUr0gTx-SBe"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(tvec, open(trained_models_path+'tvec.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWb9NkoRkp2J"
   },
   "outputs": [],
   "source": [
    "logreg_tfid = linear_model.LogisticRegression(C=0.1, penalty ='l2').fit(X_train_tvec, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYI7L9gck6tr"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(logreg_tfid, open(trained_models_path+'logreg_tfid.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGje-h8Ftdod"
   },
   "source": [
    "## 2. Naif bayésien BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3PcVSPqtdoe"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "ber = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(ber, open(trained_models_path+'ber.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZifCNkpc-DJ"
   },
   "source": [
    "##  3. Naif bayésien MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwNM8ynnc-5D"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(nb, open(trained_models_path+'nb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCG0TZMGtdop"
   },
   "source": [
    "## 4. K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9uN4E70tdoq"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=13, metric= \"minkowski\", weights = 'distance').fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(knn, open(trained_models_path+'knn.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xjukn6QbhA-F"
   },
   "source": [
    "## 5. Arbre de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iX2KZF0vhJ2O"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(dc, open(trained_models_path+'dc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1jvQDm6lee_"
   },
   "source": [
    "## 6. Forêt aléatoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulZw5D6RlZcH"
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_jobs = -1).fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(rf, open(trained_models_path+'rf.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWEFU4FfJCtD"
   },
   "source": [
    "## 7. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0K4JWVauJCtK"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(xgb, open(trained_models_path+'xgb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW6Vw1-Ibez0"
   },
   "source": [
    "## 8. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p2gmPdrbdtw"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradbt = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(gradbt, open(trained_models_path+'gradbt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_p2tQRQSRWb"
   },
   "source": [
    "## 9. Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crj2_Yu4SPCK"
   },
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "dtc_u = DecisionTreeClassifier(max_depth = 3)\n",
    "ac = AdaBoostClassifier(base_estimator = dtc_u,learning_rate = 0.1, n_estimators = 400)\n",
    "ac.fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(ac, open(trained_models_path+'ac.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100), max_iter=100, alpha=0.0001, solver='sgd', verbose=10,  random_state=21,tol=0.000000001).fit(X_train, y_train)\n",
    "\n",
    "# # Enregistrement\n",
    "# pickle.dump(mlp, open(trained_models_path+'mlp.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C. Avec le traitement de données (Corpus,POS tagging).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
