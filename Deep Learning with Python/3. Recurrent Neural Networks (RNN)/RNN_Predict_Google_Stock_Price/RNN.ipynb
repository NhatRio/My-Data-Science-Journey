{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will predict the stock price of Google! We will use LSTM for this task. We will make an LSTM that will try to capture the downward and upward tren of the Google stock price. LSTM is the most powerful model that can do this.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model on 5-years Google stock price dataset (2012-2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by data preprocessing,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Google_Stock_Price_Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1258 entries, 0 to 1257\n",
      "Data columns (total 6 columns):\n",
      "Date      1258 non-null object\n",
      "Open      1258 non-null float64\n",
      "High      1258 non-null float64\n",
      "Low       1258 non-null float64\n",
      "Close     1258 non-null object\n",
      "Volume    1258 non-null object\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 59.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we use only the Open values. You can use the others or combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature scaling, we will use Normalisation. To do this, we import MinMaxScaler from Scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc  = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Creating a data structure with 60 timesteps and 1 output.\n",
    "60 times steps here means that at each time T, the RNN is going to look at the 60 stock prices before time T,  that is the stock prices between 60 days before time T and time T, and based on the trends, it is capturing during these 60 previous timesteps, it will try to predict the next output (at time T+1).\n",
    "\n",
    "And why 60? I tried a lot of number of steps.\n",
    "\n",
    "Notice that one normal month has 20 financial days. So 60 timesteps here correspond tree months. This means that each day we are gonna look at the __tree previous month__ to try to predict the stock price the __next day__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, initializing two empty matrices, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train =  []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for loop to append values from *training_set_scaled*  to them,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60,len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, X_train and y_train are lists, we have to transfer them to array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use just \"Open\" column for training set, we can use other indicator (High, Low,...). To do this, you should reshape the dimensionalities of X_train. This change also to be compatible with the input format, input shape in RNN.\n",
    "\n",
    "(See more at https://keras.io/layers/recurrent/ - Input Shape)\n",
    "We see that  Input shape is 3D tensor with shape:\n",
    "\n",
    "<code>(batch_size, timesteps, input_dim)</code>.\n",
    "    \n",
    "   + <code>batch_size</code>: number of observations\n",
    "   + <code>input_dim</code>: number of indicators/predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just completed the data preprocessing, the data is ready to train. Now we will build the RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not gonna make a simple LSTM, we are gonna build a stacked LSTM with some dropout regulization to prevent overfitting. We use here the Keras library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential  #initialize the neural network\n",
    "from tensorflow.keras.layers import Dense # add the output layer of RNN\n",
    "from tensorflow.keras.layers import LSTM # add the LSTM layers\n",
    "from tensorflow.keras.layers import Dropout # add some dropout regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Adding layers to RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the first LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 17:46:00.188314 140735623418752 deprecation.py:506] From /Users/PhuocNhatDANG/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "regressor.add(LSTM(units = 50,return_sequences = True,input_shape=(X_train.shape[1],1)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   + <code>units</code>: number of LSTM cells\n",
    "\n",
    "   + <code>return_sequences</code>: True for non-last LSTM layer, False (Default) for last one.\n",
    "   + <code>input_shape</code>: Shape of X_train, here we don't need add the 1st dimendion of X_train ( X_train.shape[0]) because it will be automatically taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose <code>units</code> being 50. Since capturing the trends of a stock price is pretty complex, we need to have high dimensionality. Therefore, we need to have a large number of neurons in each of the multiple LSTM layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate dropout is 20% that means that 20%  of neurons of the LSTM layer will be ignored during the training (during the forward/back propgation) happening in each iteration of the training. In our case, 20% of 50 is 10 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the second LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50,return_sequences = True))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't  need input shape anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the third LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50,return_sequences = True))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the fourth LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>return_sequences</code> is False (defaut value) because this is the last LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Compiling the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant optimizers for RNN are Adam and RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Fitting the RNN model to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0912 19:36:59.526043 140735623418752 deprecation.py:323] From /Users/PhuocNhatDANG/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 11s 9ms/sample - loss: 0.0522\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 9s 7ms/sample - loss: 0.0057\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0054\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0055\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0049\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 9s 7ms/sample - loss: 0.0046\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 9s 7ms/sample - loss: 0.0045\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 9s 8ms/sample - loss: 0.0044\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 11s 9ms/sample - loss: 0.0045\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 10s 9ms/sample - loss: 0.0047\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0037\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0045\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0035\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0037\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0041\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0044\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0036\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 9s 8ms/sample - loss: 0.0039\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0038\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0037\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0035\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 9s 7ms/sample - loss: 0.0032\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0033\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0032\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 10s 8ms/sample - loss: 0.0030\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 10s 9ms/sample - loss: 0.0032\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0031\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0029\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0033\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0037\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0031\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0030\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0028\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0033\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0027\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0026\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0030\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0026\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0024\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0029\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0026\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0023\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0022\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0023\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0024\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0024\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 11s 9ms/sample - loss: 0.0025\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0028\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0023\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0022\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0022\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0024\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0021\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0021\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0022\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0023\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0022\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0019\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0021\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0020\n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0019\n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0018\n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0017\n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0019\n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 9s 7ms/sample - loss: 0.0019\n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0019\n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0017\n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0019\n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0018\n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0018\n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0019\n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0016\n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018 2s -\n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0018\n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 10s 9ms/sample - loss: 0.0016\n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 9s 8ms/sample - loss: 0.0017\n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0015\n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 94/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0016\n",
      "Epoch 97/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 7s 6ms/sample - loss: 0.0015\n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a334a3f98>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train, epochs = 100,batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,             \n",
    "    - bacth_size: the number of observations after  which you want to update the weights\n",
    "     - epochs : number of rounds that the whole training set pass through the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Making the predictions and visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Getting the real stock price of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Google_Stock_Price_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = df_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[778.81],\n",
       "       [788.36],\n",
       "       [786.08],\n",
       "       [795.26],\n",
       "       [806.4 ],\n",
       "       [807.86],\n",
       "       [805.  ],\n",
       "       [807.14],\n",
       "       [807.48],\n",
       "       [807.08],\n",
       "       [805.81],\n",
       "       [805.12],\n",
       "       [806.91],\n",
       "       [807.25],\n",
       "       [822.3 ],\n",
       "       [829.62],\n",
       "       [837.81],\n",
       "       [834.71],\n",
       "       [814.66],\n",
       "       [796.86]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2  Getting the predicted stock price of 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree points you have to notice in this section:\n",
    "\n",
    "    1. For predicting the stock price in test set, we need some days from training set. We need stock price of 60 previous financial  days to predict stock price at actual day. \n",
    "    2. To do this, we need both training set and test set. Therefore, we will concatenate the training and the test set.\n",
    "    3. DO NOT concatenate training_set (scaled training set) and real_stock_price (test set) since we have to scale this concatenation and this makes change the values of actual test values (real_stock_price). NEVER DO THIS!!! For handling this problem, we will concatenate the two original DataFrames df_train and df_test. We will scale this concatenation and use this to predict the stoke price in January 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((df_train[\"Open\"],df_test[\"Open\"]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1278,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset_total[len(df_train)-60:].values\n",
    "#or inputs = dataset_total[len(dataset_total)-len(df_set)-60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of inputs is not a Numpy array, so we need to reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1,1) #-1 means None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we scale our inputs as the same way applied on training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sc.transform(inputs) \n",
    "# no fit since we use exactly the same scaling of training_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are also creating a test data structure with 60 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, initializing an empty matrices, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for loop to append values from *inputs*  to X_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60,len(inputs)):\n",
    "    X_test.append(inputs[i-60:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to transfer X_test to array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to reshape X_test to 3D tensor for being compatible with input shape of the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time to predict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9622828 ],\n",
       "       [0.95715237],\n",
       "       [0.95670164],\n",
       "       [0.9592236 ],\n",
       "       [0.96536624],\n",
       "       [0.97602963],\n",
       "       [0.98664725],\n",
       "       [0.9919952 ],\n",
       "       [0.99306726],\n",
       "       [0.9923793 ],\n",
       "       [0.99160004],\n",
       "       [0.99102783],\n",
       "       [0.99069667],\n",
       "       [0.9914814 ],\n",
       "       [0.99312484],\n",
       "       [1.0006243 ],\n",
       "       [1.0130391 ],\n",
       "       [1.0272171 ],\n",
       "       [1.0362607 ],\n",
       "       [1.0311396 ]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the values of predicted_stock_price are derived by using the scaled test data (X_test). Therefore, for comparing predicted_stock_price to real_stock_price, we need to inverse our predictions (predicted_stock_price) to original scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[796.4047 ],\n",
       "       [793.6468 ],\n",
       "       [793.4045 ],\n",
       "       [794.76025],\n",
       "       [798.06226],\n",
       "       [803.7945 ],\n",
       "       [809.5021 ],\n",
       "       [812.37695],\n",
       "       [812.9532 ],\n",
       "       [812.5834 ],\n",
       "       [812.1645 ],\n",
       "       [811.8569 ],\n",
       "       [811.6789 ],\n",
       "       [812.1007 ],\n",
       "       [812.9842 ],\n",
       "       [817.01556],\n",
       "       [823.6893 ],\n",
       "       [831.31085],\n",
       "       [836.1723 ],\n",
       "       [833.4194 ]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot the real-predicted stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_stock_price, color = 'red',label = 'Real Google Stock Price (January 2017)')\n",
    "plt.plot(predicted_stock_price, color = 'blue',label = 'Predicted Google Stock Price (January 2017)')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we get conclusion:\n",
    "    \n",
    "    1. In the parts of the predictions containing some spikes, our predictions lag behind the actual values because our model cannot react to fast, nonlinear changes.\n",
    "\n",
    "    2. On the other hand, for the parts of the predictions containing smooth changes, our model reacts pretty well and manages to follow the upward and downward trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Improving our model.\n",
    "Here are different ways to improve the RNN model:\n",
    "\n",
    "    1. Getting more training data: we trained our model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.\n",
    "\n",
    "    2. Increasing the number of timesteps: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. That’s because we chose a number of 60 timesteps (3 months). You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n",
    "    \n",
    "    3. Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n",
    "\n",
    "    4. Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n",
    "\n",
    "    5. Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
