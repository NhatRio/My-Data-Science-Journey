{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORK with MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ #check version of tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly classify MNIST using a simple Multi-layer perceptron and then, in the second part, we use deeplearning to improve the accuracy of our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Classify MNIST using a simple model (Multi-player Perceptron-MLP )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What is MNIST?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to LeCun's website, the MNIST is a: \"database of handwritten digits that has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import the MNIST dataset using TensorFlow built-in feature</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very important to notice that MNIST is a high optimized data-set and __it does not contain images__. You will need to build your own code if you want to see the real digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an interactive section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PhuocNhatDANG/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 784]) # 784 = 28x28 pixels\n",
    "y_act = tf.placeholder(tf.float32, shape = [None, 10] ) # 10 = nb of elements from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning bias and weights to null tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now sizes of $x$, $y$ are respectively (784,1), (10,1). Hence size of $W$ (weight) is (784,10). Note that $y=W^Tx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight tensor\n",
    "W = tf.Variable(tf.zeros([784,10],tf.float32)) \n",
    "#Bias tensor\n",
    "b = tf.Variable(tf.zeros([10],tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the assignment operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the operation initialize_all_variables using an interactive session\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Weights and Biases to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_6:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(x,W)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(tf.matmul(x,W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Logistic function_ output is used for the classification between two target classes 0/1. _Softmax function_ is generalized type of logistic function. That is, Softmax can output a multiclass categorical probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cross-entropy function to determine the loss of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(p,q) = -\\sum_{x}p(x)\\log q(x)$$\n",
    "\n",
    "where $p$ is a probability of actual values and $q$ is a probability of predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_act*tf.log(y_pred),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of optimization: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several optimizers available, in our case we will use Gradient Descent because it is well established optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(learning_rate =  0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train using minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 50 training examples for each training iteration\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict = {x:batch[0], y_act: batch[1] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy for the simple ANN model is: 91.21000170707703 %\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_act,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "acc = accuracy.eval(feed_dict = {x:mnist.test.images,y_act:mnist.test.labels})*100\n",
    "print(\"The final accuracy for the simple ANN model is: {} %\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()#finish session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref5\"></a>\n",
    "<h2>How to improve our model?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Several options as follow:</h4>\n",
    "<ul>\n",
    "    <li>Regularization of Neural Networks using DropConnect</li>\n",
    "    <li>Multi-column Deep Neural Networks for Image Classification</li> \n",
    "    <li>APAC: Augmented Pattern Classification with Neural Networks</li>\n",
    "    <li>Simple Deep Neural Network with Dropout</li>\n",
    "</ul>\n",
    "<h4>In the next part we are going to explore the option:</h4>\n",
    "<ul>\n",
    "    <li>Simple Deep Neural Network with Dropout (more than 1 hidden layer)</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Classify MNIST using a Deep Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part, we learned how to use a simple ANN to classify MNIST. Now we are going to expand our knowledge using a Deep Neural Network. \n",
    "\n",
    "\n",
    "Architecture of our network is:\n",
    "    \n",
    "- (Input) -> [batch_size, 28, 28, 1]  >> Apply 32 filter of [5x5]\n",
    "- (Convolutional layer 1)  -> [batch_size, 28, 28, 32]\n",
    "- (ReLU 1)  -> [?, 28, 28, 32]\n",
    "- (Max pooling 1) -> [?, 14, 14, 32]\n",
    "- (Convolutional layer 2)  -> [?, 14, 14, 64] \n",
    "- (ReLU 2)  -> [?, 14, 14, 64] \n",
    "- (Max pooling 2)  -> [?, 7, 7, 64] \n",
    "- [fully connected layer 3] -> [1x1024]\n",
    "- [ReLU 3]  -> [1x1024]\n",
    "- [Drop out]  -> [1x1024]\n",
    "- [fully connected layer 4] -> [1x10]\n",
    "\n",
    "\n",
    "The next cells will explore this new architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#finish possible remaining session\n",
    "sess.close()\n",
    "\n",
    "#Start interaction session\n",
    "sess = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1 .The MNIST data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create general parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "witdh = 28 #witdh of the image in pixels\n",
    "height = 28 #height of the image in pixels\n",
    "flat = witdh * height # number of pixels in one image\n",
    "class_output = 10 #number of possible classifications for the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create place holders for inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape = [None, flat])\n",
    "y_act = tf.placeholder(tf.float32,shape = [None, class_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting images of the data set to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1st_ dimension: batch number (can be any size),\n",
    "\n",
    "_2nd_ dimension: height,\n",
    "\n",
    "_3rd_ dimension: width,\n",
    "\n",
    "_4th_ dimension: image channels (1 channel as grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining kernel weight and bias</h4>\n",
    "We define a kernel here. The Size of the filter/kernel is 5x5;  Input channels is 1 (grayscale);  and we need 32 different feature maps (here, 32 feature maps means 32 different filters are applied on each image. So, the output of convolution layer would be 28x28x32). In this step, we create a filter / kernel tensor of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32], stddev = 0.1 ))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape = [32] )) # 32 biases for 32 outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convolve image with weight tensor and add biases.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve1= tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_8:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the ReLu activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f(x)$ is a ReLU function,\n",
    "$$f(x)=\\max(0,x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(convolve1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = tf.nn.max_pool(h_conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')#max_pool 2x2\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First layer completed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases of kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the convolution again in this layer. Lets look at the second layer kernel:  \n",
    "- Filter/kernel: 5x5 (25 pixels) \n",
    "- Input channels: 32 (from the 1st Conv layer, we had 32 feature maps) \n",
    "- 64 output feature maps  \n",
    "\n",
    "<b>Notice:</b> here, the input image is [14x14x32], the filter is [5x5x32], we use 64 filters of size [5x5x32], and the output of the convolutional layer would be 64 convolved image, [14x14x64].\n",
    "\n",
    "<b>Notice:</b> the convolution result of applying a filter of size [5x5x32] on image of size [14x14x32] is an image of size [14x14x1], that is, the convolution is functioning on volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64], stddev = 0.1 ))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape = [64] )) # 64 biases for 64 outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convolve image with weight tensor and add biases.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the ReLu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv2 = tf.nn.relu(convolve2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = tf.nn.max_pool(h_conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')#max_pool 2x2\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second layer completed. The output of layer 2  is 64 matrices of [7x7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fully Connected Layer (Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a fully connected layer to use the Softmax and create the probabilities in the end. Fully connected layers take the high-level filtered images from previous layer, that is all 64 matrices, and convert them to a flat array.\n",
    "\n",
    "So, each matrix [7x7] will be converted to a matrix of [49x1], and then all of the 64 matrix will be connected, which make an array of size [3136x1]. We will connect it into another layer of size [1024x1]. So, the weight between these 2 layers will be [3136x1024]\n",
    "\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/pr9mnirmlrzm2bitf1d4jj389hyvv7ey.png\" alt=\"HTML5 Icon\" style=\"width: 800px; height: 400px;\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_matrix = tf.reshape(conv2,[-1,7*7*64]) # we don't care the 1st dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and biase between layer 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal([7*7*64,1024], stddev = 0.1 ))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape = [1024] )) # 1024 biases for 1024 outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication (Applying weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = tf.matmul(layer2_matrix, W_fc1)+b_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_fc1 = tf.nn.relu(fc1)\n",
    "h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third layer is completed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dropout Layer, (Optional phase for reducing overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a phase where the network \"forget\" some features. At each training step in a mini-batch, some units get switched off randomly so that it will not interact with the network. That is, it weights cannot be updated, nor affect the learning of the other network nodes.  This can be very useful for very large neural networks to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_1/mul_1:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "layer_drop = tf.nn.dropout(h_fc1, rate = 1-keep_prob)\n",
    "layer_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: p (keep_prob)=0.5 is recommended configuration, except for the input layer which is recommended to have p=0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, at testing time we treat it as a normal neural network without dropout, and at training time we upscale the values by 1/prob."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Readout Layer (Softmax Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type: Softmax, Fully Connected Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Weights and Biases</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last layer, CNN takes the high-level filtered images and translate them into votes using softmax.\n",
    "Input channels: 1024 (neurons from the 3rd Layer); 10 output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = tf.Variable(tf.truncated_normal([1024,10], stddev = 0.1 ))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape = [10] )) # 10 biases for 10 outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication (Applying weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = tf.matmul(layer_drop, W_fc2)+b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_CNN = tf.nn.softmax(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref7\"></a>\n",
    "<h2>Summary of the Deep Convolutional Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is time to remember the structure of  our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) Input - MNIST dataset\n",
    "#### 1) Convolutional and Max-Pooling\n",
    "#### 2) Convolutional and Max-Pooling\n",
    "#### 3) Fully Connected Layer\n",
    "#### 4) Processing - Dropout\n",
    "#### 5) Readout layer - Fully Connected\n",
    "#### 6) Outputs - Classified digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've completed our CNN model. Now we will train it by our MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cross-entropy function to determine the loss of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(p,q) = -\\dfrac{1}{N}\\sum_{x}p(x)\\log q(x)$$\n",
    "\n",
    "where $p$ is a probability of actual values, $q$ is a probability of predicted values and $N$ is number of instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_act*tf.log(y_CNN),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the optimizer AdamOptimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction =  tf.equal(tf.argmax(y_CNN,1),tf.argmax(y_act,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the model and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run it if you want to see the train accuracy and loss values \n",
    "\n",
    "#### Train model\n",
    "# train_accuracy=0.0\n",
    "# train_loss=0.0\n",
    "# for i in range(1100):\n",
    "#     batch = mnist.train.next_batch(50)\n",
    "#     if i%100 == 0:\n",
    "#         #train_accuracy = accuracy.eval(feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 1.0})\n",
    "#         train_accuracy, train_loss = sess.run([accuracy,cross_entropy],feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 1.0})\n",
    "#         print(\"Step %d, training accuracy %g, training loss %g\"%(i,float(train_accuracy),float(train_loss)))\n",
    "#     train_step.run(feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 0.5})\n",
    "\n",
    "\n",
    "\n",
    "##### Evaluate model\n",
    "\n",
    "# #evaluate in batches to avoid out-of-memory issues\n",
    "# n_batches = mnist.test.images.shape[0]//50\n",
    "# cumulative_accuracy = 0.0\n",
    "# for index in range(n_batches):\n",
    "#     batch = mnist.test.next_batch(50)\n",
    "#     cumulative_accuracy += accuracy.eval(feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 1.0})\n",
    "# print(\"Test accuracy {}\".format(cumulative_accuracy/n_batches))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectors for stroring accuracy and loss values\n",
    "train_accuracy = []\n",
    "train_loss = []\n",
    "test_accuracy = []\n",
    "test_loss = []\n",
    "#Setting batch size to avoid costly computation\n",
    "size_batch = 50\n",
    "train_n_batches = mnist.train.images.shape[0]//size_batch\n",
    "test_n_batches = mnist.test.images.shape[0]//size_batch\n",
    "\n",
    "for _ in range(40):\n",
    "    cumulative_train_accuracy = 0.0\n",
    "    cumulative_train_loss =0.0\n",
    "    cumulative_test_accuracy = 0.0\n",
    "    cumulative_test_loss =0.0\n",
    "    #Train the model\n",
    "    for i in range(train_n_batches):\n",
    "        batch = mnist.train.next_batch(size_batch)\n",
    "        batch_train_accuracy, batch_train_loss = sess.run([accuracy,cross_entropy],feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 1.0})\n",
    "        cumulative_train_accuracy += batch_train_accuracy\n",
    "        cumulative_train_loss += batch_train_loss\n",
    "        train_step.run(feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 0.5})\n",
    "    train_accuracy.append(cumulative_train_accuracy/train_n_batches)\n",
    "    train_loss.append(cumulative_train_loss/train_n_batches)\n",
    "    #Evaluate the model (evaluate in batches to avoid out-of-memory issues)\n",
    "    for index in range(test_n_batches):\n",
    "        batch = mnist.test.next_batch(size_batch)\n",
    "        batch_test_accuracy, batch_test_loss = sess.run([accuracy,cross_entropy],feed_dict = {x:batch[0], y_act:batch[1],keep_prob: 1.0})\n",
    "        cumulative_test_accuracy += batch_test_accuracy\n",
    "        cumulative_test_loss += batch_test_loss\n",
    "    test_accuracy.append(cumulative_test_accuracy/test_n_batches)\n",
    "    test_loss.append(cumulative_test_loss/test_n_batches)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train-validation loss and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training-Validation loss\n",
    "plt.plot(range(len(train_loss)),train_loss, color = 'b', label = \"Training Loss\" )\n",
    "plt.plot(range(len(train_loss)),test_loss, color = 'r', label = \"Test Loss\" )\n",
    "plt.title(\"Training-Test loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training-Validation Accuracy\n",
    "plt.plot(range(len(train_accuracy)),train_accuracy, color = 'b', label = \"Training accuracy\" )\n",
    "plt.plot(range(len(train_accuracy)),test_accuracy, color = 'r', label = \"Test accuracy\" )\n",
    "plt.title(\"Training-Test accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fistly, we will visualize all the filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0,1]),[32, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --output-document utils1.py http://deeplearning.net/tutorial/code/utils.py\n",
    "import utils1\n",
    "from utils1 import tile_raster_images\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "image = Image.fromarray(tile_raster_images(kernels, img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n",
    "### Plot image\n",
    "plt.rcParams['figure.figsize'] = (18.0, 18.0)\n",
    "imgplot = plt.imshow(image)\n",
    "imgplot.set_cmap('gray')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly,  we will see the output of an image passing through 1st convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (5.0,5.0)\n",
    "sampleimage = mnist.test.images[1]\n",
    "plt.imshow(np.reshape(sampleimage,[28,28]),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivatedUnits = sess.run(convolve1,feed_dict={x:np.reshape(sampleimage,[1,784],order='F'),keep_prob:1.0})\n",
    "filters = ActivatedUnits.shape[3] #remember that size of 1st convolution layer is\n",
    "                                  # [-1,28,28,32]      \n",
    "plt.figure(1, figsize=(20,20))\n",
    "n_columns = 6\n",
    "n_rows = np.math.ceil(filters / n_columns) + 1\n",
    "for i in range(filters):\n",
    "    plt.subplot(n_rows, n_columns, i+1)\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    plt.title('Image through filter ' + str(i))\n",
    "    plt.imshow(ActivatedUnits[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will see the output of an image passing through 2nd convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivatedUnits = sess.run(convolve2,feed_dict={x:np.reshape(sampleimage,[1,784],order='F'),keep_prob:1.0})\n",
    "filters = ActivatedUnits.shape[3]#size of 2nd convolution layer is\n",
    "                                  # [-1,7,7,64]\n",
    "plt.figure(1, figsize=(20,20))\n",
    "n_columns = 8\n",
    "n_rows = np.math.ceil(filters / n_columns) + 1\n",
    "for i in range(filters):\n",
    "    plt.subplot(n_rows, n_columns, i+1)\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    plt.title('Image through filter ' + str(i))\n",
    "    plt.imshow(ActivatedUnits[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
