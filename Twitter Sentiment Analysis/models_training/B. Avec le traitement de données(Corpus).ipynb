{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EL7kxZp8bUTz"
   },
   "source": [
    "**Commentaire:** _Ici, nous avons choisi ici d'entraîner le modèle sur des données traitées grâce à la fonction \"create_corpus\" qui permet de \"nettoyer\" les textes des tweets._\n",
    "\n",
    "I. Importation des packages nécessaires\n",
    "\n",
    "II. Importation du jeu de données\n",
    "\n",
    "III. Séparation des données\n",
    "\n",
    "VI. Entraînement des modèles\n",
    "\n",
    "> 1. Régression logistique\n",
    "\n",
    "> 2. Naif bayésien BernoulliNB\n",
    "\n",
    "> 3. Naif bayésien MultinomialNB\n",
    "\n",
    "> 4. K plus proches voisins\n",
    "\n",
    "> 5. Arbre de décision\n",
    "\n",
    "> 6. Forêt aléatoire\n",
    "\n",
    "> 7. XGBOOST\n",
    "\n",
    "> 8. Gradient Boosting\n",
    "\n",
    "> 9. Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eowg7a8ZbTm8"
   },
   "source": [
    "# PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21762,
     "status": "ok",
     "timestamp": 1579409998759,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "b0Rm_gN2fvy6",
    "outputId": "d871c1cd-500b-4097-93fb-895761230911",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# file_path = 'gdrive/My Drive/Colab Notebooks/SentimentAnalysisTwitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local\n",
    "file_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjNvVxZRiMfV"
   },
   "source": [
    "# I. Importation des packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22957,
     "status": "ok",
     "timestamp": 1579409999979,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "opecpP88fvzA",
    "outputId": "a56ee1a7-3908-4c7b-b21b-15f29825b6e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/PhuocNhatDANG/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize, pos_tag, sent_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyO0C38iibyO"
   },
   "source": [
    "# II. Importation du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.split(os.getcwd())[0]+'/data/data_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYGLK8MBfvzD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path +'/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26042,
     "status": "ok",
     "timestamp": 1579410003294,
     "user": {
      "displayName": "Phước Nhật Đặng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_b8xLQZxB5TfavJR3Sm5ERKsl_GcYBBWKNY-i=s64",
      "userId": "14612078459020105434"
     },
     "user_tz": -60
    },
    "id": "UN_HkDJrfvzK",
    "outputId": "ed1ba69c-16e2-4f5a-e7ea-e1cf38070ead",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tagged</th>\n",
       "      <th>clean_text_tagged_bis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot awww bummer shoulda got david carr ...</td>\n",
       "      <td>[('switchfoot', 'NN'), ('awww', 'NN'), ('bumme...</td>\n",
       "      <td>('switchfoot', 'NN'), ('awww', 'NN'), ('bummer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "      <td>[('upset', 'JJ'), ('updat', 'JJ'), ('facebook'...</td>\n",
       "      <td>('upset', 'JJ'), ('updat', 'JJ'), ('facebook',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dive mani time ball manag save 50 res...</td>\n",
       "      <td>[('kenichan', 'NNS'), ('dive', 'VBP'), ('mani'...</td>\n",
       "      <td>('kenichan', 'NNS'), ('dive', 'VBP'), ('mani',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>[('whole', 'JJ'), ('bodi', 'NN'), ('feel', 'VB...</td>\n",
       "      <td>('whole', 'JJ'), ('bodi', 'NN'), ('feel', 'VB'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "      <td>[('nationwideclass', 'NN'), ('behav', 'NN'), (...</td>\n",
       "      <td>('nationwideclass', 'NN'), ('behav', 'NN'), ('...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  target         ids                          date      flag  \\\n",
       "0      0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1      1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2      2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3      3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4      4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  switchfoot awww bummer shoulda got david carr ...   \n",
       "1  upset updat facebook text might cri result sch...   \n",
       "2  kenichan dive mani time ball manag save 50 res...   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                      nationwideclass behav mad see   \n",
       "\n",
       "                                   clean_text_tagged  \\\n",
       "0  [('switchfoot', 'NN'), ('awww', 'NN'), ('bumme...   \n",
       "1  [('upset', 'JJ'), ('updat', 'JJ'), ('facebook'...   \n",
       "2  [('kenichan', 'NNS'), ('dive', 'VBP'), ('mani'...   \n",
       "3  [('whole', 'JJ'), ('bodi', 'NN'), ('feel', 'VB...   \n",
       "4  [('nationwideclass', 'NN'), ('behav', 'NN'), (...   \n",
       "\n",
       "                               clean_text_tagged_bis  \n",
       "0  ('switchfoot', 'NN'), ('awww', 'NN'), ('bummer...  \n",
       "1  ('upset', 'JJ'), ('updat', 'JJ'), ('facebook',...  \n",
       "2  ('kenichan', 'NNS'), ('dive', 'VBP'), ('mani',...  \n",
       "3  ('whole', 'JJ'), ('bodi', 'NN'), ('feel', 'VB'...  \n",
       "4  ('nationwideclass', 'NN'), ('behav', 'NN'), ('...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_DZHnSttdn4"
   },
   "source": [
    "# III. Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f4ElnlUfgLi"
   },
   "outputs": [],
   "source": [
    "trained_models_path = file_path + 'Best_models_B/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STGSZlrRtdn4"
   },
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNVI6EU_tdn9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvJKTM3Ctdn_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRsUgxiv-BCi"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(vectorizer, open(trained_models_path+'vectorizer.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHg_9UEFjxpM"
   },
   "source": [
    "# VI. Entraînement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzmv7FRmtdoB"
   },
   "source": [
    "## 1. Régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-rjir2-tdoC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Régression logistique \n",
    "\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=0.1, penalty ='l2')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(logreg, open(trained_models_path+'logreg.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emlwEgqJtdoW"
   },
   "source": [
    "### Avec une TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyyxor47tdoW"
   },
   "outputs": [],
   "source": [
    "X_train_tf,X_test_tf,y_train_tf,y_test_tf = train_test_split(X,y,test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpyu6cAztdoY"
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "X_train_tvec = tvec.fit_transform(X_train_tf)\n",
    "X_test_tvec = tvec.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHUr0gTx-SBe"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(tvec, open(trained_models_path+'tvec.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWb9NkoRkp2J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg_tfid = linear_model.LogisticRegression(C=0.1, penalty ='l2').fit(X_train_tvec, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYI7L9gck6tr"
   },
   "outputs": [],
   "source": [
    "# Enregistrement\n",
    "pickle.dump(logreg_tfid, open(trained_models_path+'logreg_tfid.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGje-h8Ftdod"
   },
   "source": [
    "## 2. Naif bayésien BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3PcVSPqtdoe"
   },
   "outputs": [],
   "source": [
    "# Naif bayésien BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "ber = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(ber, open(trained_models_path+'ber.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZifCNkpc-DJ"
   },
   "source": [
    "##  3. Naif bayésien MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwNM8ynnc-5D"
   },
   "outputs": [],
   "source": [
    "# Naif bayésien MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(nb, open(trained_models_path+'nb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCG0TZMGtdop"
   },
   "source": [
    "## 4. K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9uN4E70tdoq"
   },
   "outputs": [],
   "source": [
    "# knn\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=13, metric= \"minkowski\", weights = 'distance').fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(knn, open(trained_models_path+'knn.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xjukn6QbhA-F"
   },
   "source": [
    "## 5. Arbre de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iX2KZF0vhJ2O"
   },
   "outputs": [],
   "source": [
    "# Arbre de décision\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(dc, open(trained_models_path+'dc.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1jvQDm6lee_"
   },
   "source": [
    "## 6. Forêt aléatoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulZw5D6RlZcH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_jobs = -1).fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(rf, open(trained_models_path+'rf.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWEFU4FfJCtD"
   },
   "source": [
    "## 7. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0K4JWVauJCtK"
   },
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(xgb, open(trained_models_path+'xgb.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW6Vw1-Ibez0"
   },
   "source": [
    "## 8. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p2gmPdrbdtw"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradbt = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(gradbt, open(trained_models_path+'gradbt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_p2tQRQSRWb"
   },
   "source": [
    "## 9. Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crj2_Yu4SPCK"
   },
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "dtc_u = DecisionTreeClassifier(max_depth = 3)\n",
    "ac = AdaBoostClassifier(base_estimator = dtc_u,learning_rate = 0.1, n_estimators = 400)\n",
    "ac.fit(X_train,y_train)\n",
    "\n",
    "# Enregistrement\n",
    "pickle.dump(ac, open(trained_models_path+'ac.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100), max_iter=100, alpha=0.0001, solver='sgd', verbose=10,  random_state=21,tol=0.000000001).fit(X_train, y_train)\n",
    "\n",
    "# # Enregistrement\n",
    "# pickle.dump(mlp, open(trained_models_path+'mlp.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "B. Avec le traitement de données(Corpus).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
